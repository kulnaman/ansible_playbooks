heat_template_version: 2013-05-23

description: >
  Heat template to set up an MPI cluster on Chameleon Cloud with a specific network configuration.

parameters:
  key_name:
    type: string
    label: Key name
    description: Name of a key pair to enable SSH access to the instance
    default: default
    constraints:
    - custom_constraint: nova.keypair
  network_name:
    type: string
    description: ID of the share network to use
    constraints:
    - custom_constraint: neutron.network
  subnet_name:
    type: string
    description: name of the existing subnet to use
  reservation_id:
    type: string
    description: ID of the Blazar reservation to use for launching instances
    constraints:
    - custom_constraint: blazar.reservation
  router_interface_ip:
    type: string
    description: IP address for the router interface
  node_count:
    type: number
    label: Node count
    description: Number of physical nodes
    default: 1
    constraints:
      - range: { min: 1 }
        description: There must be at least one physical node.

resources:
  router_to_ext:
    type: OS::Neutron::Router
    properties:
      name: router
      external_gateway_info:
        network: public

  my_subnet_port:
    type: OS::Neutron::Port
    properties:
      network_id: { get_param: network_name }
      fixed_ips:
        - subnet: { get_param: subnet_name }
          ip_address: { get_param: router_interface_ip }

  router_interface:
    type: OS::Neutron::RouterInterface
    properties:
      router: { get_resource: router_to_ext }
      # subnet: { get_resource: subnet }
      port_id: { get_resource: my_subnet_port }

  mpi_keypair:
    type: OS::Nova::KeyPair
    properties:
      save_private_key: true
      name:
        str_replace:
          template: mpi_stack_id
          params:
            stack_id: { get_param: "OS::stack_id" }

  instance_floating_ip:
    type: OS::Nova::FloatingIP
    properties:
      pool: public

  instance_association:
    type: OS::Nova::FloatingIPAssociation
    properties:
      floating_ip: { get_resource: instance_floating_ip }
      server_id: { get_attr: [mpi_cluster, resource.0] }
      
    
  export_hosts:
    type: OS::Heat::SoftwareConfig
    properties:
      outputs:
        - name: hosts
      group: script
      config: |
        #!/bin/sh
        (echo -n $(facter ipaddress); echo -n ' '; echo $(hostname)) > ${heat_outputs_path}.hosts

  export_hosts_sdg:
    type: OS::Heat::SoftwareDeploymentGroup
    # depends_on: delay_wait_condition
    properties:
      config: { get_resource: export_hosts }
      servers: { get_attr: [mpi_cluster, refs_map] }
      signal_transport: HEAT_SIGNAL

  populate_hosts:
    type: OS::Heat::SoftwareConfig
    properties:
      inputs:
        - name: hosts
      group: script
      config: |
        mkdir -p /etc/flux
        mkdir -p /etc/flux/security/conf.d
        mkdir -p /etc/flux/imp/conf.d
        mkdir -p /etc/flux/system/conf.d

        #!/usr/bin/env python
        import ast
        import os
        import subprocess
        hosts = os.getenv('hosts')
        if hosts is not None:
            hosts = ast.literal_eval(hosts.replace('\n', '\\n'))
        with open('/etc/hosts', 'a') as hosts_file:
          for ip_host in hosts.values():
              hosts_file.write(ip_host.rstrip() + '\n')

  populate_hosts_sdg:
    type: OS::Heat::SoftwareDeploymentGroup
    depends_on: export_hosts_sdg
    properties:
      config: { get_resource: populate_hosts }
      servers: { get_attr: [mpi_cluster, refs_map] }
      signal_transport: HEAT_SIGNAL
      input_values:
        hosts: { get_attr: [ export_hosts_sdg, hosts ] }
      
  # configure_ansible_deployment:
  #   type: OS::Heat::SoftwareDeployment
  #   properties:
  #     config: { get_resource:  configure_ansible}
  #     servers: { get_attr: [mpi_cluster, refs_map] }
  #     # Other properties as needed
  #   depends_on: mpi_cluster

  install_hwloc-source:
    type: OS::Heat::SoftwareDeploymentGroup
    depends_on: [populate_hosts_sdg, mpi_cluster]
    properties:
      signal_transport: HEAT_SIGNAL
      config: { get_resource: configure_install_hwloc }
      servers: { get_attr: [mpi_cluster, refs_map] }
      # Other properties as needed

  rocm_installation_config:
    type: OS::Heat::SoftwareConfig
    properties:
      group: script
      config: |
        #!/bin/bash
        sleep 120
        echo "Starting ROCm installation"
        sudo amdgpu-install -y --accept-eula --usecase=rocm > amd_result.txt
        if [ $? -eq 0 ]; then
            echo "ROCM installation successful"
        else
            echo "ROCM installation failed"
            exit 1
        fi

  rocm_installation_deployment:
    type: OS::Heat::SoftwareDeploymentGroup
    depends_on: [populate_hosts_sdg, mpi_cluster]
    properties:
      config: { get_resource: rocm_installation_config }
      servers: { get_attr: [mpi_cluster, refs_map] }
      signal_transport: HEAT_SIGNAL

  mpi_config_sdg:
    type: OS::Heat::SoftwareDeploymentGroup
    depends_on:  mpi_cluster
    properties:
      config: { get_resource: user_data_software_config }
      servers: { get_attr: [mpi_cluster, refs_map] }
      signal_transport: HEAT_SIGNAL
      
  mpi_cluster:
    type: OS::Heat::ResourceGroup
    properties:
      count: { get_param: node_count }
      resource_def:
        type: OS::Nova::Server
        properties:
          name: flux%index%
          image: Ubuntu22.04_MVAPICH_kernel_6.3          
          flavor: baremetal
          key_name: { get_param: key_name }
          networks:
            - network: sharednet1
            - network: { get_param: network_name }
          scheduler_hints: { reservation: { get_param: reservation_id } }
          software_config_transport: POLL_SERVER_HEAT
          # user_data: { get_resource: user_data_software_config }

  configure_install_hwloc: 
    type: OS::Heat::SoftwareConfig
    properties:
      group: script
      config: |
        #!/bin/bash
        # Check if this is the master node
        sudo apt install wget
        wget https://download.open-mpi.org/release/hwloc/v2.10/hwloc-2.10.0.tar.gz
        tar -zxvf hwloc-2.10.0
        cd hwloc-2.10.0
        export C_INCLUDE_PATH=/opt/rocm/include
        export LIBRARY_PATH=/opt/rocm/lib
        ./configure --enable-rsmi
        make -j128
        sudo make install



   # configure_ansible:
   #    type: OS::Heat::SoftwareConfig
   #    properties:
   #      group: script
   #      config: |
   #        #!/bin/bash
   #        # Check if this is the master node
   #        if [ "$(hostname)" = "flux0" ]; then
   #          # Install Git
   #          sudo apt-get update && apt-get install -y git
   #
   #          mkdir -p /home/ubuntu/ansible/playbooks
   #          # Install Ansible (if not already installed)
   #          apt-get install ansible -y
   #          # Clone the playbook repository
   #          git clone https://github.com/kulnaman/ansible_playbooks.git /home/ubuntu/ansible/playbooks
   #
   #          # Run the Ansible playbooks
   #          cd /home/ubuntu/ansible/playbooks
   #          ansible-playbook your-playbook.yml
   #          # Add commands to run more playbooks if needed
   #        fi
        # Add any other configurations as needed
  user_data_software_config:
    type: OS::Heat::SoftwareConfig
    properties:
      config:
        str_replace:
          template: |
            #cloud-config
            bootcmd:
              - touch /tmp/system_up.marker
            runcmd:
              - |
                # Wait until the system is fully up
                while [ ! -f /tmp/system_up.marker ]; do
                  sleep 10
                done
                sleep 900
                # Setup SSH access keys
                cd /home/cc/.ssh/
                cat << EOF > id_rsa.pub
                public_key
                EOF
                cat << EOF > id_rsa
                private_key
                EOF
                cat << EOF > config
                Host *
                  StrictHostKeyChecking no
                EOF
                cat id_rsa.pub >> authorized_keys
                chmod 600 authorized_keys id_rsa
                chmod 644 id_rsa.pub config
                sudo chown cc:cc *

                # Configure hosts file
                cd /home/cc/
                for i in `seq 0 $(node_count_placeholder)`; do
                  echo "flux$i.novalocal" >> hosts
                done
                sudo chown cc:cc hosts

                # Set environment variable for MPI
                echo "export HYDRA_HOST_FILE=/home/cc/hosts" >> /home/cc/.bash_profile

          params:
            private_key: { get_attr: [ mpi_keypair, private_key ] }
            public_key: { get_attr: [ mpi_keypair, public_key ] }
            node_count_placeholder: { get_param: node_count }

outputs:
    first_instance_ip:
      description: The public IP address of the first instance. Login with the command 'ssh cc@first_instance_ip'.
      value: { get_attr: [instance_floating_ip, ip] }
    deployment_results:
      description: The private IPs and hostnames of all deployed instances
      value: { get_attr: [export_hosts_sdg, hosts] }
    rocm_installation_output:
      description: ROCm installation status for each instance
      value: { get_attr: [rocm_installation_deployment, status] }
